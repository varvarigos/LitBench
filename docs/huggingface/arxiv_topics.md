# arXiv Topics

## Dataset Summary

The arXiv Topics Dataset provides a structured mapping of arXiv papers to topic categories at three different levels of abstraction. These topic classifications were generated by prompting GPT-4, ensuring a hierarchical categorization from broad fields to highly specific research areas.

The dataset consists of 2,422,486 paper IDs, each assigned topics across:

- Level 1 (Broad Domains): High-level fields such as Computer Science, Mathematics, Physics, etc.

- Level 2 (Intermediate Categories): More detailed areas like Linguistics, Quantum Computing, Theoretical Machine Learning, etc.

- Level 3 (Specific Research Topics): Granular classifications such as Large Language Models, Neural Network Optimization, Few-Shot Learning, etc.

This dataset can be used for document classification, topic modeling, retrieval augmentation, and other AI-driven literature applications.

## Dataset Structure

### Data Fields

Each paper ID is mapped to a JSON object with the following structure:
'''python
{
  "paper_id": "2401.12345",
  "topics": {
    "Level 1": ["Physics", "Mathematics", "Chemistry"],
    "Level 2": ["Nuclear Physics", "Theoretical Physics", "Quantum Mechanics"],
    "Level 3": ["Nuclear Density Functional", "Particle-Boson Coupling", "Nuclear Spectroscopy"]
  }
}
'''

- paper_id: Unique identifier for the paper (following arXiv ID format).

- Level 1: Broad research domains.

- Level 2: More refined subfields.

- Level 3: Specific research topics, suitable for fine-grained categorization.

### Usage

To load the dataset using datasets:
'''python
from datasets import load_dataset

arXiv_topics = load_dataset("AliMaatouk/arXiv_Topics")

# Example: Retrieve topics for the first paper
sample_paper = arxiv_topics['train'][0]
print(f"Paper ID: {sample_paper['paper_id']}")
print(f"Level 1 Topics: {sample_paper['topics']['Level 1']}")
print(f"Level 2 Topics: {sample_paper['topics']['Level 2']}")
print(f"Level 3 Topics: {sample_paper['topics']['Level 3']}")
'''

This dataset is particularly useful for domain specific retriveal, LLM fine-tuning, citation graph analysis, literature retrieval systems, and automated research assistance.

## Citation

If you use the arXiv Topics Dataset in your research, please cite our work:

@misc{litbench2024topics,
  title={LitBench: A Large Language Model Benchmarking Framework For Literature Tasks},
  author={Your Name and Co-authors},
  year={2025}
}

For further details about the LitBench framework, refer to our main repository: [LitBench GitHub](https://www.example.com).
